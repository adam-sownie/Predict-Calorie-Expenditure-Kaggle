{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e826f7-8e9b-4af6-9514-289ea4161b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle API Dataset Download\n",
    "# This section handles downloading and accessing the dataset for the Playground Series S5E5 competition\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# This cell detects whether we're running on Kaggle or locally\n",
    "IN_KAGGLE = os.path.exists('/kaggle/input')\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    # If running on Kaggle, the data is already available in the /kaggle/input directory\n",
    "    print(\"Running on Kaggle - dataset already available\")\n",
    "\n",
    "    # Competition data paths\n",
    "    BASE_DIR = '/kaggle/input/playground-series-s5e5'\n",
    "\n",
    "else:\n",
    "    # If running locally, we need to download the data via the Kaggle API\n",
    "    print(\"Running locally - downloading data via Kaggle API\")\n",
    "\n",
    "    # First, check if kaggle module is installed\n",
    "    try:\n",
    "        import kaggle\n",
    "    except ImportError:\n",
    "        print(\"Kaggle API not found. Installing...\")\n",
    "        !pip install kaggle\n",
    "        import kaggle\n",
    "\n",
    "    # Create directory for data if it doesn't exist\n",
    "    os.makedirs('kaggle_data', exist_ok=True)\n",
    "\n",
    "    # Download competition data\n",
    "    # Note: You need to have your Kaggle API credentials in ~/.kaggle/kaggle.json\n",
    "    # If not already set up, run the following commands in a cell:\n",
    "    \"\"\"\n",
    "    # Run this if you haven't set up Kaggle API credentials:\n",
    "    !mkdir -p ~/.kaggle\n",
    "    !echo '{\"username\":\"YOUR_USERNAME\",\"key\":\"YOUR_KEY\"}' > ~/.kaggle/kaggle.json\n",
    "    !chmod 600 ~/.kaggle/kaggle.json\n",
    "    \"\"\"\n",
    "\n",
    "    # Download all competition files\n",
    "    !kaggle competitions download -c playground-series-s5e5 -p kaggle_data\n",
    "\n",
    "    # Unzip the downloaded files\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile('kaggle_data/playground-series-s5e5.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('kaggle_data')\n",
    "\n",
    "    print(\"Dataset downloaded successfully!\")\n",
    "\n",
    "    # Set the base directory for data access\n",
    "    BASE_DIR = 'kaggle_data'\n",
    "\n",
    "# Now let's define paths to access the files in a consistent way\n",
    "# This will work both on Kaggle and locally\n",
    "train_path = os.path.join(BASE_DIR, 'train.csv')\n",
    "test_path = os.path.join(BASE_DIR, 'test.csv')\n",
    "sample_submission_path = os.path.join(BASE_DIR, 'sample_submission.csv')\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "sample_submission = pd.read_csv(sample_submission_path)\n",
    "\n",
    "# Display basic information about the datasets\n",
    "print(\"\\n--- Dataset Information ---\")\n",
    "print(f\"Training set shape: {train_df.shape}\")\n",
    "print(f\"Test set shape: {test_df.shape}\")\n",
    "print(f\"Sample submission shape: {sample_submission.shape}\")\n",
    "\n",
    "# Display a few rows of the training data\n",
    "print(\"\\n--- First few rows of training data ---\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26677b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calorie Prediction Model Training\n",
    "\n",
    "## 1. Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## 2. Create the dataset from the provided data\n",
    "\n",
    "df = train_df\n",
    "\n",
    "## 3. Exploratory Data Analysis (EDA)\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nDataset information:\")\n",
    "print(df.info())\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Visualize the target variable distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['Calories'], bins=10, edgecolor='black')\n",
    "plt.title('Distribution of Calories')\n",
    "plt.xlabel('Calories')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Convert categorical to numerical first\n",
    "df['Sex'] = df['Sex'].map({'male': 1, 'female': 0})\n",
    "\n",
    "# Correlation matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = df.drop('id', axis=1).corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Pairplot to visualize relationships between features\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.pairplot(df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'Calories']])\n",
    "plt.suptitle('Pairplot of Numerical Features', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "## 4. Feature Engineering and Preprocessing\n",
    "# Separate features and target\n",
    "X = df.drop(['id', 'Calories'], axis=1)\n",
    "y = df['Calories']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "## 5. Build and Evaluate Different Models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R2': r2\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name} Results:\")\n",
    "    print(f\"MSE: {mse:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"R2 Score: {r2:.2f}\")\n",
    "\n",
    "## 6. Hyperparameter Tuning for the Best Model\n",
    "# Select the best model based on R2 score\n",
    "best_model_name = max(results, key=lambda x: results[x]['R2'])\n",
    "print(f\"\\nThe best model based on R2 score is: {best_model_name}\")\n",
    "\n",
    "# Hyperparameter tuning for the best model\n",
    "if best_model_name == 'Random Forest':\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "elif best_model_name == 'Gradient Boosting':\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.8, 0.9, 1.0]\n",
    "    }\n",
    "    model = GradientBoostingRegressor(random_state=42)\n",
    "elif best_model_name == 'Ridge Regression':\n",
    "    param_grid = {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "    }\n",
    "    model = Ridge()\n",
    "elif best_model_name == 'Lasso Regression':\n",
    "    param_grid = {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "    }\n",
    "    model = Lasso()\n",
    "else:  # Linear Regression has no hyperparameters to tune\n",
    "    print(\"Linear Regression has no hyperparameters to tune.\")\n",
    "    \n",
    "if best_model_name != 'Linear Regression':\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=3, scoring='r2', n_jobs=-1)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    print(f\"\\nBest hyperparameters for {best_model_name}:\")\n",
    "    print(grid_search.best_params_)\n",
    "    \n",
    "    # Evaluate the tuned model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\nTuned {best_model_name} Results:\")\n",
    "    print(f\"MSE: {mse:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"R2 Score: {r2:.2f}\")\n",
    "\n",
    "## 7. Feature Importance Analysis\n",
    "if best_model_name in ['Random Forest', 'Gradient Boosting']:\n",
    "    if best_model_name != 'Linear Regression':\n",
    "        best_model = grid_search.best_estimator_\n",
    "    else:\n",
    "        best_model = models[best_model_name]\n",
    "    \n",
    "    # Get feature importance\n",
    "    importances = best_model.feature_importances_\n",
    "    feature_names = X.columns\n",
    "    \n",
    "    # Sort features by importance\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(f'Feature Importance - {best_model_name}')\n",
    "    plt.bar(range(X.shape[1]), importances[indices], align='center')\n",
    "    plt.xticks(range(X.shape[1]), [feature_names[i] for i in indices], rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nFeature Importance:\")\n",
    "    for i in indices:\n",
    "        print(f\"{feature_names[i]}: {importances[i]:.4f}\")\n",
    "\n",
    "## 8. Final Model and Predictions\n",
    "# Train the final model on the entire dataset\n",
    "if best_model_name != 'Linear Regression':\n",
    "    final_model = grid_search.best_estimator_\n",
    "else:\n",
    "    final_model = LinearRegression()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "final_model.fit(X_scaled, y)\n",
    "\n",
    "# Function to predict calories for new data\n",
    "def predict_calories(data_dict):\n",
    "    \"\"\"\n",
    "    Predict calories for new data.\n",
    "    \n",
    "    Parameters:\n",
    "    data_dict (dict): Dictionary with keys as feature names and values as feature values\n",
    "                     Example: {'Sex': 'male', 'Age': 30, 'Height': 175, 'Weight': 70, \n",
    "                              'Duration': 20, 'Heart_Rate': 95, 'Body_Temp': 40}\n",
    "    \n",
    "    Returns:\n",
    "    float: Predicted calories\n",
    "    \"\"\"\n",
    "    # Convert to DataFrame\n",
    "    new_data = pd.DataFrame([data_dict])\n",
    "    \n",
    "    # Convert categorical to numerical\n",
    "    if 'Sex' in new_data.columns:\n",
    "        new_data['Sex'] = new_data['Sex'].map({'male': 1, 'female': 0})\n",
    "    \n",
    "    # Scale the features\n",
    "    new_data_scaled = scaler.transform(new_data)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = final_model.predict(new_data_scaled)[0]\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# Example usage\n",
    "example_data = {\n",
    "    'Sex': 'male',\n",
    "    'Age': 30,\n",
    "    'Height': 175,\n",
    "    'Weight': 70,\n",
    "    'Duration': 20,\n",
    "    'Heart_Rate': 95,\n",
    "    'Body_Temp': 40\n",
    "}\n",
    "\n",
    "predicted_calories = predict_calories(example_data)\n",
    "print(f\"\\nPredicted calories for example data: {predicted_calories:.2f}\")\n",
    "\n",
    "## 9. Model Evaluation on Training Data\n",
    "# Create a function to visualize actual vs predicted values\n",
    "def plot_actual_vs_predicted(y_true, y_pred, title):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_true, y_pred)\n",
    "    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], 'r--')\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Get predictions on the entire dataset\n",
    "y_pred_all = final_model.predict(X_scaled)\n",
    "\n",
    "# Plot actual vs predicted\n",
    "plot_actual_vs_predicted(y, y_pred_all, 'Actual vs Predicted Calories')\n",
    "\n",
    "# Calculate metrics for the entire dataset\n",
    "mse_all = mean_squared_error(y, y_pred_all)\n",
    "rmse_all = np.sqrt(mse_all)\n",
    "mae_all = mean_absolute_error(y, y_pred_all)\n",
    "r2_all = r2_score(y, y_pred_all)\n",
    "\n",
    "print(\"\\nFinal Model Evaluation on All Data:\")\n",
    "print(f\"MSE: {mse_all:.2f}\")\n",
    "print(f\"RMSE: {rmse_all:.2f}\")\n",
    "print(f\"MAE: {mae_all:.2f}\")\n",
    "print(f\"R2 Score: {r2_all:.2f}\")\n",
    "\n",
    "## 10. Save the model (optional)\n",
    "# If you want to save the model for future use, uncomment the following code\n",
    "'''\n",
    "import joblib\n",
    "joblib.dump(final_model, 'calorie_prediction_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "print(\"Model and scaler saved successfully!\")\n",
    "'''\n",
    "\n",
    "## 11. Conclusion\n",
    "print(\"\\nModel Training Summary:\")\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "print(f\"Sample size: {len(df)} records\")\n",
    "print(f\"Features used: {', '.join(X.columns)}\")\n",
    "print(f\"Target variable: Calories\")\n",
    "print(f\"Model performance (R2 Score): {r2_all:.2f}\")\n",
    "print(\"\\nLimitations:\")\n",
    "print(\"- Small dataset size may limit model generalization\")\n",
    "print(\"- More features might be needed for better accuracy\")\n",
    "print(\"- Additional data collection recommended for improved predictions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
