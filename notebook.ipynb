{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e826f7-8e9b-4af6-9514-289ea4161b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle API Dataset Download\n",
    "# This section handles downloading and accessing the dataset for the Playground Series S5E5 competition\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# This cell detects whether we're running on Kaggle or locally\n",
    "IN_KAGGLE = os.path.exists('/kaggle/input')\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    # If running on Kaggle, the data is already available in the /kaggle/input directory\n",
    "    print(\"Running on Kaggle - dataset already available\")\n",
    "\n",
    "    # Competition data paths\n",
    "    BASE_DIR = '/kaggle/input/playground-series-s5e5'\n",
    "\n",
    "else:\n",
    "    # If running locally, we need to download the data via the Kaggle API\n",
    "    print(\"Running locally - downloading data via Kaggle API\")\n",
    "\n",
    "    # First, check if kaggle module is installed\n",
    "    try:\n",
    "        import kaggle\n",
    "    except ImportError:\n",
    "        print(\"Kaggle API not found. Installing...\")\n",
    "        !pip install kaggle\n",
    "        import kaggle\n",
    "\n",
    "    # Create directory for data if it doesn't exist\n",
    "    os.makedirs('kaggle_data', exist_ok=True)\n",
    "\n",
    "    # Download competition data\n",
    "    # Note: You need to have your Kaggle API credentials in ~/.kaggle/kaggle.json\n",
    "    # If not already set up, run the following commands in a cell:\n",
    "    \"\"\"\n",
    "    # Run this if you haven't set up Kaggle API credentials:\n",
    "    !mkdir -p ~/.kaggle\n",
    "    !echo '{\"username\":\"YOUR_USERNAME\",\"key\":\"YOUR_KEY\"}' > ~/.kaggle/kaggle.json\n",
    "    !chmod 600 ~/.kaggle/kaggle.json\n",
    "    \"\"\"\n",
    "\n",
    "    # Download all competition files\n",
    "    !kaggle competitions download -c playground-series-s5e5 -p kaggle_data\n",
    "\n",
    "    # Unzip the downloaded files\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile('kaggle_data/playground-series-s5e5.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('kaggle_data')\n",
    "\n",
    "    print(\"Dataset downloaded successfully!\")\n",
    "\n",
    "    # Set the base directory for data access\n",
    "    BASE_DIR = 'kaggle_data'\n",
    "\n",
    "# Now let's define paths to access the files in a consistent way\n",
    "# This will work both on Kaggle and locally\n",
    "train_path = os.path.join(BASE_DIR, 'train.csv')\n",
    "test_path = os.path.join(BASE_DIR, 'test.csv')\n",
    "sample_submission_path = os.path.join(BASE_DIR, 'sample_submission.csv')\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "sample_submission = pd.read_csv(sample_submission_path)\n",
    "\n",
    "# Display basic information about the datasets\n",
    "print(\"\\n--- Dataset Information ---\")\n",
    "print(f\"Training set shape: {train_df.shape}\")\n",
    "print(f\"Test set shape: {test_df.shape}\")\n",
    "print(f\"Sample submission shape: {sample_submission.shape}\")\n",
    "\n",
    "# Display a few rows of the training data\n",
    "print(\"\\n--- First few rows of training data ---\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb29f79-0631-4826-af61-b7bb52deb79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    # Original preprocessing\n",
    "    if 'id' in df.columns:\n",
    "        df = df.drop('id', axis=1)\n",
    "    df['Intensity'] = df['Heart_Rate'] * df['Duration']\n",
    "    df['TotalTemp'] = df['Body_Temp'] * df['Duration']\n",
    "    df['Sex'] = pd.Categorical(df.Sex)\n",
    "\n",
    "    df['Temp_Heart_Interaction'] = df['Body_Temp'] * df['Heart_Rate']\n",
    "    df['HR_Times_Weight'] = df['Heart_Rate'] * df['Weight']\n",
    "    df['Est_Max_HR'] = 220 - df['Age']\n",
    "    df['Age_Based_HR_Percent'] = df['Heart_Rate'] / df['Est_Max_HR']\n",
    "    df['BMI'] = df['Weight'] / (df['Height'] ** 2)\n",
    "\n",
    "    df['Temp_Heart_Interaction_Duration'] = df['Temp_Heart_Interaction'] * df['Duration']\n",
    "    df['HR_Times_Weight_Times_Duration'] = df['HR_Times_Weight'] * df['Duration']\n",
    "    df['Age_Based_Intensity'] = df['Age_Based_HR_Percent'] * df['Duration']\n",
    "    df['BMI_Intensity'] = df['BMI'] * df['Intensity']\n",
    "    \n",
    "    # Calculate VOâ‚‚-Based Calorie Estimate\n",
    "    # Step 1: Estimate VOâ‚‚_max (mL/kg/min) - using a simplified age-based estimate\n",
    "    # A common simple estimate is 45.2 - 0.35*Age for men, slightly lower for women\n",
    "    # We'll use an average approach of 40 - 0.25*Age for simplicity\n",
    "    vo2_max = 40 - 0.25 * df['Age']\n",
    "    \n",
    "    # Step 2: Calculate estimated VOâ‚‚ during exercise based on heart rate\n",
    "    # Assuming HR is linearly related to VOâ‚‚ consumption (simplified model)\n",
    "    # MaxHR estimated as 208 - 0.7 * Age\n",
    "    max_hr = 208 - 0.7 * df['Age']\n",
    "    hr_percentage = df['Heart_Rate'] / max_hr\n",
    "    vo2_estimate = vo2_max * hr_percentage\n",
    "    \n",
    "    # Step 3: Calculate total Oâ‚‚ consumed in liters\n",
    "    # Total Oâ‚‚ = VOâ‚‚ (mL/kg/min) Ã— Weight(kg) Ã— Duration(min) / 1000\n",
    "    total_o2_consumed = vo2_estimate * df['Weight'] * df['Duration'] / 1000\n",
    "    \n",
    "    # Step 4: Convert Oâ‚‚ to calories (5 kcal per liter of Oâ‚‚)\n",
    "    df['VO2_Calories'] = total_o2_consumed * 5\n",
    "\n",
    "    is_male = df['Sex'] == 'male'\n",
    "    \n",
    "    # Calculate calories per minute based on the formulas\n",
    "    male_calories_per_min = (-55.0969 + 0.6309 * df['Heart_Rate'] + \n",
    "                            0.1988 * df['Weight'] + \n",
    "                            0.2017 * df['Age']) / 4.184\n",
    "    \n",
    "    female_calories_per_min = (-20.4022 + 0.4472 * df['Heart_Rate'] - \n",
    "                              0.1263 * df['Weight'] + \n",
    "                              0.074 * df['Age']) / 4.184\n",
    "    \n",
    "    # Assign the appropriate calculation based on sex\n",
    "    df['Calories_Per_Minute'] = np.where(is_male, male_calories_per_min, female_calories_per_min)\n",
    "    \n",
    "    # Calculate total calories based on duration\n",
    "    df['HR_Based_Calories'] = df['Calories_Per_Minute'] * df['Duration']\n",
    "\n",
    "    if 'Intensity' in df.columns:\n",
    "        df = df.drop('Intensity', axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "orig_test_df = test_df\n",
    "train_df = preprocess_df(train_df)\n",
    "test_df = preprocess_df(test_df)\n",
    "cats=['Sex']\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26677b87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Training XGBoost with robust RMSLE optimization...\")\n",
    "X = train_df.drop('Calories', axis=1)\n",
    "y = train_df['Calories']\n",
    "\n",
    "# Create train/validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identify categorical features\n",
    "cat_features = ['Sex']\n",
    "\n",
    "# Apply one-hot encoding for categorical features (XGBoost doesn't handle categorical features directly like CatBoost)\n",
    "X_train_encoded = pd.get_dummies(X_train, columns=cat_features, drop_first=True)\n",
    "X_val_encoded = pd.get_dummies(X_val, columns=cat_features, drop_first=True)\n",
    "\n",
    "# Log-transform targets\n",
    "y_train_log = np.log1p(np.maximum(0, y_train))\n",
    "y_val_log = np.log1p(np.maximum(0, y_val))\n",
    "\n",
    "# XGBoost configuration - parameters chosen to be similar to the CatBoost setup\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=3000,\n",
    "    learning_rate=0.01,        # Reduced learning rate for stability\n",
    "    max_depth=8,               # Similar depth as CatBoost\n",
    "    objective='reg:squarederror',  # MSE objective for log-transformed data\n",
    "    eval_metric='rmsle',        # Standard RMSE evaluation\n",
    "    random_state=42,\n",
    "    verbosity=1,\n",
    "    reg_lambda=5,              # L2 regularization similar to l2_leaf_reg\n",
    "    min_child_weight=10,       # Similar to min_data_in_leaf\n",
    "    subsample=0.8,             # Add some subsampling for robustness\n",
    "    colsample_bytree=0.8       # Feature subsampling\n",
    ")\n",
    "\n",
    "# Train the model on log-transformed targets with early stopping\n",
    "# Note: early_stopping_rounds should be provided as a parameter to fit_params, not directly to fit()\n",
    "eval_set = [(X_val_encoded, y_val_log)]\n",
    "xgb_model.fit(\n",
    "    X_train_encoded, \n",
    "    y_train_log,\n",
    "    eval_set=eval_set,\n",
    ")\n",
    "\n",
    "# Make predictions (on log scale) and transform back\n",
    "val_predictions_log = xgb_model.predict(X_val_encoded)\n",
    "val_predictions = np.expm1(val_predictions_log)  # expm1 is inverse of log1p\n",
    "\n",
    "# Ensure predictions are non-negative (should already be due to exp transform)\n",
    "val_predictions = np.maximum(0, val_predictions)\n",
    "\n",
    "# Calculate RMSLE directly\n",
    "def rmsle(y_true, y_pred):\n",
    "    # Ensure inputs are positive\n",
    "    y_true = np.maximum(0, y_true)\n",
    "    y_pred = np.maximum(0, y_pred)\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "\n",
    "# Evaluate the model\n",
    "val_mse = mean_squared_error(y_val, val_predictions)\n",
    "val_rmse = np.sqrt(val_mse)\n",
    "val_rmsle = rmsle(y_val, val_predictions)\n",
    "val_r2 = r2_score(y_val, val_predictions)\n",
    "\n",
    "print(f\"Validation MSE: {val_mse:.2f}\")\n",
    "print(f\"Validation RMSE: {val_rmse:.2f}\")\n",
    "print(f\"Validation RMSLE: {val_rmsle:.4f}\")  # This is your target metric\n",
    "print(f\"Validation RÂ²: {val_r2:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "importance = xgb_model.feature_importances_\n",
    "feature_names = X_train_encoded.columns\n",
    "importance_df = sorted(zip(feature_names, importance), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "for name, importance in importance_df:\n",
    "    print(f\"{name}: {importance}\")\n",
    "\n",
    "# If you need to predict on test data later\n",
    "# test_encoded = pd.get_dummies(test_df, columns=cat_features, drop_first=True)\n",
    "# test_predictions_log = xgb_model.predict(test_encoded)\n",
    "# test_predictions = np.expm1(test_predictions_log)\n",
    "# test_predictions = np.maximum(0, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40445001-5b27-4500-aa3e-9c43c3fa1d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nGenerating predictions for test set...\")\n",
    "X_test = test_df\n",
    "\n",
    "# We need to apply the same one-hot encoding to the test data\n",
    "# First, identify categorical features\n",
    "cat_features = ['Sex']\n",
    "\n",
    "# Apply one-hot encoding for categorical features\n",
    "X_test_encoded = pd.get_dummies(X_test, columns=cat_features, drop_first=True)\n",
    "\n",
    "# Ensure the columns match exactly with training data\n",
    "# Get the columns from the trained model (might be accessible via feature_names_in_)\n",
    "train_columns = X_train_encoded.columns\n",
    "\n",
    "# Check if any columns are missing in the test data\n",
    "missing_cols = set(train_columns) - set(X_test_encoded.columns)\n",
    "# Add missing columns with default value of 0\n",
    "for col in missing_cols:\n",
    "    X_test_encoded[col] = 0\n",
    "    \n",
    "# Ensure columns are in the same order as training data\n",
    "X_test_encoded = X_test_encoded[train_columns]\n",
    "\n",
    "# Make predictions (these are still in log space)\n",
    "test_predictions_log = xgb_model.predict(X_test_encoded)\n",
    "\n",
    "# Transform back from log space to original scale\n",
    "test_predictions = np.expm1(test_predictions_log)  # This is the inverse of log1p\n",
    "\n",
    "# Ensure predictions are non-negative (although expm1 should always give positive values)\n",
    "test_predictions = np.maximum(0, test_predictions)\n",
    "\n",
    "# Create the submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'id': orig_test_df['id'],\n",
    "    'Calories': test_predictions\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f\"Submission file created: submission.csv with {submission.shape[0]} rows\")\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"\\nFirst few rows of the submission file:\")\n",
    "display(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953b774c-8a0f-45be-b086-b7a90ce7af12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running on Kaggle or locally\n",
    "IN_KAGGLE = os.path.exists('/kaggle/working')\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    # If running on Kaggle, use the built-in submission mechanism\n",
    "    print(\"Running on Kaggle - please use the 'Submit' button in the UI to submit your results\")\n",
    "else:\n",
    "    # If running locally, use the Kaggle API to submit\n",
    "    print(\"Submitting via Kaggle API...\")\n",
    "    \n",
    "    # Ensure Kaggle API is installed\n",
    "    try:\n",
    "        import kaggle\n",
    "    except ImportError:\n",
    "        print(\"Kaggle API not found. Installing...\")\n",
    "        !pip install kaggle\n",
    "        import kaggle\n",
    "    \n",
    "    # Submit the file\n",
    "    # Note: Make sure you have Kaggle API credentials set up (~/.kaggle/kaggle.json)\n",
    "    competition_name = \"playground-series-s5e5\"\n",
    "    submission_message = \"xgboost with feature engineering\"\n",
    "    \n",
    "    # Command to submit \n",
    "    submission_command = f\"kaggle competitions submit -c {competition_name} -f submission.csv -m \\\"{submission_message}\\\"\"\n",
    "    \n",
    "    print(f\"Running command: {submission_command}\")\n",
    "    !{submission_command}\n",
    "    \n",
    "    # Check your submissions (optional)\n",
    "    print(\"\\nYour recent submissions:\")\n",
    "    !kaggle competitions submissions -c {competition_name}\n",
    "    \n",
    "print(\"\\nDone! ðŸŽ‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b108a0-e67a-4eea-9505-7d5df78683fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3261f4-4402-4a66-8b82-9eee65330870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FastAI (GPU)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
