{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e826f7-8e9b-4af6-9514-289ea4161b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle API Dataset Download\n",
    "# This section handles downloading and accessing the dataset for the Playground Series S5E5 competition\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# This cell detects whether we're running on Kaggle or locally\n",
    "IN_KAGGLE = os.path.exists('/kaggle/input')\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    # If running on Kaggle, the data is already available in the /kaggle/input directory\n",
    "    print(\"Running on Kaggle - dataset already available\")\n",
    "\n",
    "    # Competition data paths\n",
    "    BASE_DIR = '/kaggle/input/playground-series-s5e5'\n",
    "\n",
    "else:\n",
    "    # If running locally, we need to download the data via the Kaggle API\n",
    "    print(\"Running locally - downloading data via Kaggle API\")\n",
    "\n",
    "    # First, check if kaggle module is installed\n",
    "    try:\n",
    "        import kaggle\n",
    "    except ImportError:\n",
    "        print(\"Kaggle API not found. Installing...\")\n",
    "        !pip install kaggle\n",
    "        import kaggle\n",
    "\n",
    "    # Create directory for data if it doesn't exist\n",
    "    os.makedirs('kaggle_data', exist_ok=True)\n",
    "\n",
    "    # Download competition data\n",
    "    # Note: You need to have your Kaggle API credentials in ~/.kaggle/kaggle.json\n",
    "    # If not already set up, run the following commands in a cell:\n",
    "    \"\"\"\n",
    "    # Run this if you haven't set up Kaggle API credentials:\n",
    "    !mkdir -p ~/.kaggle\n",
    "    !echo '{\"username\":\"YOUR_USERNAME\",\"key\":\"YOUR_KEY\"}' > ~/.kaggle/kaggle.json\n",
    "    !chmod 600 ~/.kaggle/kaggle.json\n",
    "    \"\"\"\n",
    "\n",
    "    # Download all competition files\n",
    "    !kaggle competitions download -c playground-series-s5e5 -p kaggle_data\n",
    "\n",
    "    # Unzip the downloaded files\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile('kaggle_data/playground-series-s5e5.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('kaggle_data')\n",
    "\n",
    "    print(\"Dataset downloaded successfully!\")\n",
    "\n",
    "    # Set the base directory for data access\n",
    "    BASE_DIR = 'kaggle_data'\n",
    "\n",
    "# Now let's define paths to access the files in a consistent way\n",
    "# This will work both on Kaggle and locally\n",
    "train_path = os.path.join(BASE_DIR, 'train.csv')\n",
    "test_path = os.path.join(BASE_DIR, 'test.csv')\n",
    "sample_submission_path = os.path.join(BASE_DIR, 'sample_submission.csv')\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "sample_submission = pd.read_csv(sample_submission_path)\n",
    "\n",
    "# Display basic information about the datasets\n",
    "print(\"\\n--- Dataset Information ---\")\n",
    "print(f\"Training set shape: {train_df.shape}\")\n",
    "print(f\"Test set shape: {test_df.shape}\")\n",
    "print(f\"Sample submission shape: {sample_submission.shape}\")\n",
    "\n",
    "# Display a few rows of the training data\n",
    "print(\"\\n--- First few rows of training data ---\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb29f79-0631-4826-af61-b7bb52deb79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    df['Intensity'] = df['Heart_Rate'] * df['Duration']\n",
    "    df['TotalTemp'] = df['Body_Temp'] * df['Duration']\n",
    "    df['Sex'] = pd.Categorical(df.Sex)\n",
    "\n",
    "    return df\n",
    "\n",
    "train_df = preprocess_df(train_df)\n",
    "test_df = preprocess_df(test_df)\n",
    "\n",
    "cats=['Sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b926e206-9bf4-41c1-a15c-24c8583758f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26677b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "print(\"Training LightGBM with robust RMSLE optimization...\")\n",
    "X = train_df.drop('Calories', axis=1)\n",
    "y = train_df['Calories']\n",
    "\n",
    "# Create train/validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identify categorical features\n",
    "cat_features = ['Sex']\n",
    "if train_df['Sex'].dtype == 'object':\n",
    "    train_df['Sex'] = train_df['Sex'].astype('category').cat.codes\n",
    "cat_indices = [X.columns.get_loc(col) for col in cat_features]  # LightGBM needs indices\n",
    "\n",
    "# Use the same approach with MSE on log-transformed targets\n",
    "# Add a small constant to ensure all values are positive\n",
    "y_train_log = np.log1p(np.maximum(0, y_train))\n",
    "y_val_log = np.log1p(np.maximum(0, y_val))\n",
    "\n",
    "# LightGBM configuration similar to the CatBoost setup\n",
    "lgb_model = LGBMRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.01,        # Reduced learning rate for stability\n",
    "    max_depth=6,               # Equivalent to depth in CatBoost\n",
    "    objective='rmse',          # Standard RMSE on log-transformed data\n",
    "    metric='rmse',             # Standard RMSE evaluation\n",
    "    random_state=42,\n",
    "    verbosity=1,               # Similar to verbose in CatBoost\n",
    "    reg_lambda=5,              # L2 regularization, similar to l2_leaf_reg\n",
    "    min_child_samples=10,      # Similar to min_data_in_leaf\n",
    "    subsample=0.8,             # Add some bagging for robustness\n",
    "    colsample_bytree=0.8,      # Feature subsampling for robustness\n",
    ")\n",
    "\n",
    "# Train the model on log-transformed targets\n",
    "lgb_model.fit(\n",
    "    X_train, y_train_log,\n",
    "    eval_set=[(X_val, y_val_log)],\n",
    "    categorical_feature=cat_indices,\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=50),\n",
    "        lgb.log_evaluation(period=200)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Make predictions (on log scale) and transform back\n",
    "val_predictions_log = lgb_model.predict(X_val)\n",
    "val_predictions = np.expm1(val_predictions_log)  # expm1 is inverse of log1p\n",
    "\n",
    "# Ensure predictions are non-negative (should already be due to exp transform)\n",
    "val_predictions = np.maximum(0, val_predictions)\n",
    "\n",
    "# Calculate RMSLE directly\n",
    "def rmsle(y_true, y_pred):\n",
    "    # Ensure inputs are positive\n",
    "    y_true = np.maximum(0, y_true)\n",
    "    y_pred = np.maximum(0, y_pred)\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "\n",
    "val_mse = mean_squared_error(y_val, val_predictions)\n",
    "val_rmse = np.sqrt(val_mse)\n",
    "val_rmsle = rmsle(y_val, val_predictions)\n",
    "val_r2 = r2_score(y_val, val_predictions)\n",
    "\n",
    "print(f\"Validation MSE: {val_mse:.2f}\")\n",
    "print(f\"Validation RMSE: {val_rmse:.2f}\")\n",
    "print(f\"Validation RMSLE: {val_rmsle:.4f}\")  # This is your target metric\n",
    "print(f\"Validation RÂ²: {val_r2:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = lgb_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "importance_df = sorted(zip(feature_names, feature_importance), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "for name, importance in importance_df:\n",
    "    print(f\"{name}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40445001-5b27-4500-aa3e-9c43c3fa1d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nGenerating predictions for test set...\")\n",
    "X_test = test_df\n",
    "\n",
    "# Make predictions (these are still in log space)\n",
    "test_predictions_log = lgb_model.predict(X_test)\n",
    "\n",
    "# Transform back from log space to original scale\n",
    "test_predictions = np.expm1(test_predictions_log)  # This is the inverse of log1p\n",
    "\n",
    "# Ensure predictions are non-negative (although expm1 should always give positive values)\n",
    "test_predictions = np.maximum(0, test_predictions)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'] if 'id' in test_df.columns else range(len(test_predictions)),\n",
    "    'Calories': test_predictions\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f\"Submission file created: submission.csv with {submission.shape[0]} rows\")\n",
    "\n",
    "# Display the first few rows\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953b774c-8a0f-45be-b086-b7a90ce7af12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running on Kaggle or locally\n",
    "IN_KAGGLE = os.path.exists('/kaggle/working')\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    # If running on Kaggle, use the built-in submission mechanism\n",
    "    print(\"Running on Kaggle - please use the 'Submit' button in the UI to submit your results\")\n",
    "else:\n",
    "    # If running locally, use the Kaggle API to submit\n",
    "    print(\"Submitting via Kaggle API...\")\n",
    "    \n",
    "    # Ensure Kaggle API is installed\n",
    "    try:\n",
    "        import kaggle\n",
    "    except ImportError:\n",
    "        print(\"Kaggle API not found. Installing...\")\n",
    "        !pip install kaggle\n",
    "        import kaggle\n",
    "    \n",
    "    # Submit the file\n",
    "    # Note: Make sure you have Kaggle API credentials set up (~/.kaggle/kaggle.json)\n",
    "    competition_name = \"playground-series-s5e5\"\n",
    "    submission_message = \"Improved Catboost\"\n",
    "    \n",
    "    # Command to submit \n",
    "    submission_command = f\"kaggle competitions submit -c {competition_name} -f submission.csv -m \\\"{submission_message}\\\"\"\n",
    "    \n",
    "    print(f\"Running command: {submission_command}\")\n",
    "    !{submission_command}\n",
    "    \n",
    "    # Check your submissions (optional)\n",
    "    print(\"\\nYour recent submissions:\")\n",
    "    !kaggle competitions submissions -c {competition_name}\n",
    "    \n",
    "print(\"\\nDone! ðŸŽ‰\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FastAI (GPU)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
