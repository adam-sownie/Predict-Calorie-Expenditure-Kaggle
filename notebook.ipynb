{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e826f7-8e9b-4af6-9514-289ea4161b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle API Dataset Download\n",
    "# This section handles downloading and accessing the dataset for the Playground Series S5E5 competition\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# This cell detects whether we're running on Kaggle or locally\n",
    "IN_KAGGLE = os.path.exists('/kaggle/input')\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    # If running on Kaggle, the data is already available in the /kaggle/input directory\n",
    "    print(\"Running on Kaggle - dataset already available\")\n",
    "\n",
    "    # Competition data paths\n",
    "    BASE_DIR = '/kaggle/input/playground-series-s5e5'\n",
    "\n",
    "else:\n",
    "    # If running locally, we need to download the data via the Kaggle API\n",
    "    print(\"Running locally - downloading data via Kaggle API\")\n",
    "\n",
    "    # First, check if kaggle module is installed\n",
    "    try:\n",
    "        import kaggle\n",
    "    except ImportError:\n",
    "        print(\"Kaggle API not found. Installing...\")\n",
    "        !pip install kaggle\n",
    "        import kaggle\n",
    "\n",
    "    # Create directory for data if it doesn't exist\n",
    "    os.makedirs('kaggle_data', exist_ok=True)\n",
    "\n",
    "    # Download competition data\n",
    "    # Note: You need to have your Kaggle API credentials in ~/.kaggle/kaggle.json\n",
    "    # If not already set up, run the following commands in a cell:\n",
    "    \"\"\"\n",
    "    # Run this if you haven't set up Kaggle API credentials:\n",
    "    !mkdir -p ~/.kaggle\n",
    "    !echo '{\"username\":\"YOUR_USERNAME\",\"key\":\"YOUR_KEY\"}' > ~/.kaggle/kaggle.json\n",
    "    !chmod 600 ~/.kaggle/kaggle.json\n",
    "    \"\"\"\n",
    "\n",
    "    # Download all competition files\n",
    "    !kaggle competitions download -c playground-series-s5e5 -p kaggle_data\n",
    "\n",
    "    # Unzip the downloaded files\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile('kaggle_data/playground-series-s5e5.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('kaggle_data')\n",
    "\n",
    "    print(\"Dataset downloaded successfully!\")\n",
    "\n",
    "    # Set the base directory for data access\n",
    "    BASE_DIR = 'kaggle_data'\n",
    "\n",
    "# Now let's define paths to access the files in a consistent way\n",
    "# This will work both on Kaggle and locally\n",
    "train_path = os.path.join(BASE_DIR, 'train.csv')\n",
    "test_path = os.path.join(BASE_DIR, 'test.csv')\n",
    "sample_submission_path = os.path.join(BASE_DIR, 'sample_submission.csv')\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "sample_submission = pd.read_csv(sample_submission_path)\n",
    "\n",
    "# Display basic information about the datasets\n",
    "print(\"\\n--- Dataset Information ---\")\n",
    "print(f\"Training set shape: {train_df.shape}\")\n",
    "print(f\"Test set shape: {test_df.shape}\")\n",
    "print(f\"Sample submission shape: {sample_submission.shape}\")\n",
    "\n",
    "# Display a few rows of the training data\n",
    "print(\"\\n--- First few rows of training data ---\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb29f79-0631-4826-af61-b7bb52deb79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    # Original preprocessing\n",
    "    if 'id' in df.columns:\n",
    "        df = df.drop('id', axis=1)\n",
    "    df['Intensity'] = df['Heart_Rate'] * df['Duration']\n",
    "    df['TotalTemp'] = df['Body_Temp'] * df['Duration']\n",
    "    df['Sex'] = pd.Categorical(df.Sex)\n",
    "\n",
    "    df['Temp_Heart_Interaction'] = df['Body_Temp'] * df['Heart_Rate']\n",
    "    df['HR_Times_Weight'] = df['Heart_Rate'] * df['Weight']\n",
    "    df['Est_Max_HR'] = 220 - df['Age']\n",
    "    df['Age_Based_HR_Percent'] = df['Heart_Rate'] / df['Est_Max_HR']\n",
    "    df['BMI'] = df['Weight'] / (df['Height'] ** 2)\n",
    "\n",
    "    df['Temp_Heart_Interaction_Duration'] = df['Temp_Heart_Interaction'] * df['Duration']\n",
    "    df['HR_Times_Weight_Times_Duration'] = df['HR_Times_Weight'] * df['Duration']\n",
    "    df['Age_Based_Intensity'] = df['Age_Based_HR_Percent'] * df['Duration']\n",
    "    df['BMI_Intensity'] = df['BMI'] * df['Intensity']\n",
    "    \n",
    "    # Calculate VOâ‚‚-Based Calorie Estimate\n",
    "    # Step 1: Estimate VOâ‚‚_max (mL/kg/min) - using a simplified age-based estimate\n",
    "    # A common simple estimate is 45.2 - 0.35*Age for men, slightly lower for women\n",
    "    # We'll use an average approach of 40 - 0.25*Age for simplicity\n",
    "    vo2_max = 40 - 0.25 * df['Age']\n",
    "    \n",
    "    # Step 2: Calculate estimated VOâ‚‚ during exercise based on heart rate\n",
    "    # Assuming HR is linearly related to VOâ‚‚ consumption (simplified model)\n",
    "    # MaxHR estimated as 208 - 0.7 * Age\n",
    "    max_hr = 208 - 0.7 * df['Age']\n",
    "    hr_percentage = df['Heart_Rate'] / max_hr\n",
    "    vo2_estimate = vo2_max * hr_percentage\n",
    "    \n",
    "    # Step 3: Calculate total Oâ‚‚ consumed in liters\n",
    "    # Total Oâ‚‚ = VOâ‚‚ (mL/kg/min) Ã— Weight(kg) Ã— Duration(min) / 1000\n",
    "    total_o2_consumed = vo2_estimate * df['Weight'] * df['Duration'] / 1000\n",
    "    \n",
    "    # Step 4: Convert Oâ‚‚ to calories (5 kcal per liter of Oâ‚‚)\n",
    "    df['VO2_Calories'] = total_o2_consumed * 5\n",
    "\n",
    "    is_male = df['Sex'] == 'male'\n",
    "    \n",
    "    # Calculate calories per minute based on the formulas\n",
    "    male_calories_per_min = (-55.0969 + 0.6309 * df['Heart_Rate'] + \n",
    "                            0.1988 * df['Weight'] + \n",
    "                            0.2017 * df['Age']) / 4.184\n",
    "    \n",
    "    female_calories_per_min = (-20.4022 + 0.4472 * df['Heart_Rate'] - \n",
    "                              0.1263 * df['Weight'] + \n",
    "                              0.074 * df['Age']) / 4.184\n",
    "    \n",
    "    # Assign the appropriate calculation based on sex\n",
    "    df['Calories_Per_Minute'] = np.where(is_male, male_calories_per_min, female_calories_per_min)\n",
    "    \n",
    "    # Calculate total calories based on duration\n",
    "    df['HR_Based_Calories'] = df['Calories_Per_Minute'] * df['Duration']\n",
    "\n",
    "    if 'Intensity' in df.columns:\n",
    "        df = df.drop('Intensity', axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "orig_test_df = test_df\n",
    "train_df = preprocess_df(train_df)\n",
    "test_df = preprocess_df(test_df)\n",
    "cats=['Sex']\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26677b87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def train_xgboost_model(train_df, target_column='Calories', cat_features=['Sex'], \n",
    "                        test_size=0.2, random_state=42, verbose=True):\n",
    "    \"\"\"\n",
    "    Train an XGBoost model with RMSLE optimization using log transformation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    train_df : pd.DataFrame\n",
    "        Training dataframe containing features and target\n",
    "    target_column : str, default='Calories'\n",
    "        Name of the target column\n",
    "    cat_features : list, default=['Sex']\n",
    "        List of categorical feature column names\n",
    "    test_size : float, default=0.2\n",
    "        Proportion of data to use for validation\n",
    "    random_state : int, default=42\n",
    "        Random seed for reproducibility\n",
    "    verbose : bool, default=True\n",
    "        Whether to print training progress and results\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing:\n",
    "        - 'model': Trained XGBoost model\n",
    "        - 'metrics': Dictionary with validation metrics\n",
    "        - 'feature_importance': List of tuples (feature_name, importance)\n",
    "        - 'predictions': Validation predictions\n",
    "        - 'X_val': Validation features (encoded)\n",
    "        - 'y_val': Validation targets\n",
    "        - 'X_train': Training features (encoded)\n",
    "    \"\"\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Training XGBoost with robust RMSLE optimization...\")\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = train_df.drop(target_column, axis=1)\n",
    "    y = train_df[target_column]\n",
    "    \n",
    "    # Create train/validation split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Apply one-hot encoding for categorical features (XGBoost doesn't handle categorical features directly)\n",
    "    X_train_encoded = pd.get_dummies(X_train, columns=cat_features, drop_first=True)\n",
    "    X_val_encoded = pd.get_dummies(X_val, columns=cat_features, drop_first=True)\n",
    "    \n",
    "    # Log-transform targets\n",
    "    y_train_log = np.log1p(np.maximum(0, y_train))\n",
    "    y_val_log = np.log1p(np.maximum(0, y_val))\n",
    "    \n",
    "    # XGBoost configuration - parameters chosen to be similar to the CatBoost setup\n",
    "    xgb_model = XGBRegressor(\n",
    "        n_estimators=3000,\n",
    "        learning_rate=0.01,        # Reduced learning rate for stability\n",
    "        max_depth=8,               # Similar depth as CatBoost\n",
    "        objective='reg:squarederror',  # MSE objective for log-transformed data\n",
    "        eval_metric='rmsle',        # Standard RMSE evaluation\n",
    "        random_state=random_state,\n",
    "        verbosity=1 if verbose else 0,\n",
    "        reg_lambda=5,              # L2 regularization similar to l2_leaf_reg\n",
    "        min_child_weight=10,       # Similar to min_data_in_leaf\n",
    "        subsample=0.8,             # Add some subsampling for robustness\n",
    "        colsample_bytree=0.8       # Feature subsampling\n",
    "    )\n",
    "    \n",
    "    # Train the model on log-transformed targets with early stopping\n",
    "    eval_set = [(X_val_encoded, y_val_log)]\n",
    "    xgb_model.fit(\n",
    "        X_train_encoded, \n",
    "        y_train_log,\n",
    "        eval_set=eval_set,\n",
    "    )\n",
    "    \n",
    "    # Make predictions (on log scale) and transform back\n",
    "    val_predictions_log = xgb_model.predict(X_val_encoded)\n",
    "    val_predictions = np.expm1(val_predictions_log)  # expm1 is inverse of log1p\n",
    "    val_predictions = np.maximum(0, val_predictions)  # Ensure non-negative\n",
    "    \n",
    "    # Calculate metrics\n",
    "    def rmsle(y_true, y_pred):\n",
    "        \"\"\"Calculate Root Mean Squared Logarithmic Error\"\"\"\n",
    "        y_true = np.maximum(0, y_true)\n",
    "        y_pred = np.maximum(0, y_pred)\n",
    "        return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "    \n",
    "    val_mse = mean_squared_error(y_val, val_predictions)\n",
    "    val_rmse = np.sqrt(val_mse)\n",
    "    val_rmsle = rmsle(y_val, val_predictions)\n",
    "    val_r2 = r2_score(y_val, val_predictions)\n",
    "    \n",
    "    metrics = {\n",
    "        'mse': val_mse,\n",
    "        'rmse': val_rmse,\n",
    "        'rmsle': val_rmsle,\n",
    "        'r2': val_r2\n",
    "    }\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Validation MSE: {val_mse:.2f}\")\n",
    "        print(f\"Validation RMSE: {val_rmse:.2f}\")\n",
    "        print(f\"Validation RMSLE: {val_rmsle:.4f}\")  # Target metric\n",
    "        print(f\"Validation RÂ²: {val_r2:.4f}\")\n",
    "    \n",
    "    # Feature importance\n",
    "    importance = xgb_model.feature_importances_\n",
    "    feature_names = X_train_encoded.columns\n",
    "    importance_list = sorted(\n",
    "        zip(feature_names, importance), \n",
    "        key=lambda x: x[1], \n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\nFeature Importance:\")\n",
    "        for name, importance in importance_list:\n",
    "            print(f\"{name}: {importance}\")\n",
    "    \n",
    "    return {\n",
    "        'model': xgb_model,\n",
    "        'metrics': metrics,\n",
    "        'feature_importance': importance_list,\n",
    "        'predictions': val_predictions,\n",
    "        'X_val': X_val_encoded,\n",
    "        'y_val': y_val,\n",
    "        'X_train': X_train_encoded\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39191ebf-2b0b-4b6a-bab6-c28c4778a5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_1 = train_xgboost_model(\n",
    "    train_df=train_df,\n",
    "    target_column='Calories',\n",
    "    cat_features=['Sex'],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Print information from xgboost_1\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"XGBOOST_1 RESULTS SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"Model Type: {type(xgboost_1['model']).__name__}\")\n",
    "print(f\"Number of estimators: {xgboost_1['model'].n_estimators}\")\n",
    "\n",
    "print(f\"\\nValidation Metrics:\")\n",
    "print(f\"  RMSLE: {xgboost_1['metrics']['rmsle']:.4f}\")\n",
    "print(f\"  RMSE:  {xgboost_1['metrics']['rmse']:.2f}\")\n",
    "print(f\"  RÂ²:    {xgboost_1['metrics']['r2']:.4f}\")\n",
    "\n",
    "print(f\"\\nTop 5 Most Important Features:\")\n",
    "for i, (feature, importance) in enumerate(xgboost_1['feature_importance'][:5]):\n",
    "    print(f\"  {i+1}. {feature}: {importance:.4f}\")\n",
    "\n",
    "print(f\"\\nValidation Set Info:\")\n",
    "print(f\"  Validation samples: {len(xgboost_1['y_val'])}\")\n",
    "print(f\"  Prediction range: {xgboost_1['predictions'].min():.1f} - {xgboost_1['predictions'].max():.1f}\")\n",
    "print(f\"  Actual range: {xgboost_1['y_val'].min():.1f} - {xgboost_1['y_val'].max():.1f}\")\n",
    "print(f\"  Encoded features: {len(xgboost_1['X_train'].columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab10a0b-4912-45ba-a14b-dbd26a8e2676",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def train_catboost_model(train_df, target_column='Calories', cat_features=['Sex'], \n",
    "                        test_size=0.2, random_state=42, verbose=True):\n",
    "    \"\"\"\n",
    "    Train a CatBoost model with RMSLE optimization using log transformation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    train_df : pd.DataFrame\n",
    "        Training dataframe containing features and target\n",
    "    target_column : str, default='Calories'\n",
    "        Name of the target column\n",
    "    cat_features : list, default=['Sex']\n",
    "        List of categorical feature column names\n",
    "    test_size : float, default=0.2\n",
    "        Proportion of data to use for validation\n",
    "    random_state : int, default=42\n",
    "        Random seed for reproducibility\n",
    "    verbose : bool, default=True\n",
    "        Whether to print training progress and results\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing:\n",
    "        - 'model': Trained CatBoost model\n",
    "        - 'metrics': Dictionary with validation metrics\n",
    "        - 'feature_importance': List of tuples (feature_name, importance)\n",
    "        - 'predictions': Validation predictions\n",
    "        - 'X_val': Validation features\n",
    "        - 'y_val': Validation targets\n",
    "    \"\"\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Training CatBoost with robust RMSLE optimization...\")\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = train_df.drop(target_column, axis=1)\n",
    "    y = train_df[target_column]\n",
    "    \n",
    "    # Create train/validation split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Log transform targets for more stable training\n",
    "    y_train_log = np.log1p(np.maximum(0, y_train))\n",
    "    y_val_log = np.log1p(np.maximum(0, y_val))\n",
    "    \n",
    "    # Configure CatBoost model\n",
    "    cb_model = CatBoostRegressor(\n",
    "        iterations=1000,\n",
    "        learning_rate=0.01,         # Reduced learning rate for stability\n",
    "        depth=6,                    # Reduced depth\n",
    "        loss_function='RMSE',       # Standard RMSE on log-transformed data\n",
    "        eval_metric='RMSE',         # Standard RMSE evaluation\n",
    "        random_seed=random_state,\n",
    "        verbose=200 if verbose else False,\n",
    "        l2_leaf_reg=5,              # Increased regularization\n",
    "        min_data_in_leaf=10,        # Increased to avoid overfitting on noise\n",
    "        max_ctr_complexity=1,       # Simplify categorical feature handling\n",
    "    )\n",
    "    \n",
    "    # Train the model on log-transformed targets\n",
    "    cb_model.fit(\n",
    "        X_train, y_train_log, \n",
    "        eval_set=(X_val, y_val_log),\n",
    "        cat_features=cat_features,\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "    \n",
    "    # Make predictions and transform back to original scale\n",
    "    val_predictions_log = cb_model.predict(X_val)\n",
    "    val_predictions = np.expm1(val_predictions_log)  # expm1 is inverse of log1p\n",
    "    val_predictions = np.maximum(0, val_predictions)  # Ensure non-negative\n",
    "    \n",
    "    # Calculate metrics\n",
    "    def rmsle(y_true, y_pred):\n",
    "        \"\"\"Calculate Root Mean Squared Logarithmic Error\"\"\"\n",
    "        y_true = np.maximum(0, y_true)\n",
    "        y_pred = np.maximum(0, y_pred)\n",
    "        return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "    \n",
    "    val_mse = mean_squared_error(y_val, val_predictions)\n",
    "    val_rmse = np.sqrt(val_mse)\n",
    "    val_rmsle = rmsle(y_val, val_predictions)\n",
    "    val_r2 = r2_score(y_val, val_predictions)\n",
    "    \n",
    "    metrics = {\n",
    "        'mse': val_mse,\n",
    "        'rmse': val_rmse,\n",
    "        'rmsle': val_rmsle,\n",
    "        'r2': val_r2\n",
    "    }\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Validation MSE: {val_mse:.2f}\")\n",
    "        print(f\"Validation RMSE: {val_rmse:.2f}\")\n",
    "        print(f\"Validation RMSLE: {val_rmsle:.4f}\")  # Target metric\n",
    "        print(f\"Validation RÂ²: {val_r2:.4f}\")\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = cb_model.get_feature_importance()\n",
    "    feature_names = X.columns\n",
    "    importance_list = sorted(\n",
    "        zip(feature_names, feature_importance), \n",
    "        key=lambda x: x[1], \n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\nFeature Importance:\")\n",
    "        for name, importance in importance_list:\n",
    "            print(f\"{name}: {importance}\")\n",
    "    \n",
    "    return {\n",
    "        'model': cb_model,\n",
    "        'metrics': metrics,\n",
    "        'feature_importance': importance_list,\n",
    "        'predictions': val_predictions,\n",
    "        'X_val': X_val,\n",
    "        'y_val': y_val\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f721ea-8e95-46c8-9a99-fdeb320dd596",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_1 = train_catboost_model(\n",
    "    train_df=train_df,\n",
    "    target_column='Calories',\n",
    "    cat_features=['Sex'],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35eed2b-b69e-493a-9bae-22982771ab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CATBOOST_1 RESULTS SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"Model Type: {type(catboost_1['model']).__name__}\")\n",
    "print(f\"Number of iterations trained: {catboost_1['model'].get_best_iteration()}\")\n",
    "\n",
    "print(f\"\\nValidation Metrics:\")\n",
    "print(f\"  RMSLE: {catboost_1['metrics']['rmsle']:.4f}\")\n",
    "print(f\"  RMSE:  {catboost_1['metrics']['rmse']:.2f}\")\n",
    "print(f\"  RÂ²:    {catboost_1['metrics']['r2']:.4f}\")\n",
    "\n",
    "print(f\"\\nTop 5 Most Important Features:\")\n",
    "for i, (feature, importance) in enumerate(catboost_1['feature_importance'][:5]):\n",
    "    print(f\"  {i+1}. {feature}: {importance:.2f}\")\n",
    "\n",
    "print(f\"\\nValidation Set Info:\")\n",
    "print(f\"  Validation samples: {len(catboost_1['y_val'])}\")\n",
    "print(f\"  Prediction range: {catboost_1['predictions'].min():.1f} - {catboost_1['predictions'].max():.1f}\")\n",
    "print(f\"  Actual range: {catboost_1['y_val'].min():.1f} - {catboost_1['y_val'].max():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40445001-5b27-4500-aa3e-9c43c3fa1d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CATBOOST PREDICTIONS\n",
    "# =============================================================================\n",
    "print(\"Generating CatBoost predictions...\")\n",
    "\n",
    "# Prepare test data\n",
    "X_test = test_df\n",
    "\n",
    "# CatBoost can handle categorical features directly\n",
    "catboost_predictions_log = catboost_1['model'].predict(X_test)\n",
    "catboost_predictions = np.expm1(catboost_predictions_log)\n",
    "catboost_predictions = np.maximum(0, catboost_predictions)\n",
    "\n",
    "print(f\"CatBoost predictions range: {catboost_predictions.min():.1f} - {catboost_predictions.max():.1f}\")\n",
    "print(f\"CatBoost validation RMSLE: {catboost_1['metrics']['rmsle']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec59d595-ae86-4fcc-9981-1d4f96658cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# XGBOOST PREDICTIONS\n",
    "# =============================================================================\n",
    "print(\"Generating XGBoost predictions...\")\n",
    "\n",
    "# Prepare test data with one-hot encoding\n",
    "X_test = test_df\n",
    "cat_features = ['Sex']\n",
    "\n",
    "# Apply one-hot encoding for XGBoost (same as training)\n",
    "X_test_encoded = pd.get_dummies(X_test, columns=cat_features, drop_first=True)\n",
    "\n",
    "# Get the columns from the trained XGBoost model\n",
    "train_columns = xgboost_1['X_train'].columns\n",
    "\n",
    "# Check if any columns are missing in the test data\n",
    "missing_cols = set(train_columns) - set(X_test_encoded.columns)\n",
    "# Add missing columns with default value of 0\n",
    "for col in missing_cols:\n",
    "    X_test_encoded[col] = 0\n",
    "\n",
    "# Ensure columns are in the same order as training data\n",
    "X_test_encoded = X_test_encoded[train_columns]\n",
    "\n",
    "# Make XGBoost predictions\n",
    "xgboost_predictions_log = xgboost_1['model'].predict(X_test_encoded)\n",
    "xgboost_predictions = np.expm1(xgboost_predictions_log)\n",
    "xgboost_predictions = np.maximum(0, xgboost_predictions)\n",
    "\n",
    "print(f\"XGBoost predictions range: {xgboost_predictions.min():.1f} - {xgboost_predictions.max():.1f}\")\n",
    "print(f\"XGBoost validation RMSLE: {xgboost_1['metrics']['rmsle']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73003dd5-99b1-4798-896f-239e3ef12def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MODEL COMPARISON AND ANALYSIS\n",
    "# =============================================================================\n",
    "print(\"Analyzing model predictions...\")\n",
    "\n",
    "# Create ensemble predictions (simple average)\n",
    "ensemble_predictions = (catboost_predictions + xgboost_predictions) / 2\n",
    "\n",
    "print(f\"Ensemble predictions range: {ensemble_predictions.min():.1f} - {ensemble_predictions.max():.1f}\")\n",
    "\n",
    "# Display prediction comparison (first 10 rows)\n",
    "print(\"\\nPrediction Comparison (first 10 rows):\")\n",
    "comparison_df = pd.DataFrame({\n",
    "    'id': orig_test_df['id'][:10],\n",
    "    'CatBoost': catboost_predictions[:10],\n",
    "    'XGBoost': xgboost_predictions[:10],\n",
    "    'Ensemble': ensemble_predictions[:10],\n",
    "    'Difference': np.abs(catboost_predictions[:10] - xgboost_predictions[:10])\n",
    "})\n",
    "print(comparison_df.round(2))\n",
    "\n",
    "# Model agreement statistics\n",
    "print(f\"\\nModel Agreement Statistics:\")\n",
    "print(f\"Mean absolute difference: {np.mean(np.abs(catboost_predictions - xgboost_predictions)):.2f}\")\n",
    "print(f\"Max absolute difference: {np.max(np.abs(catboost_predictions - xgboost_predictions)):.2f}\")\n",
    "print(f\"Correlation between models: {np.corrcoef(catboost_predictions, xgboost_predictions)[0,1]:.4f}\")\n",
    "\n",
    "# Validation performance comparison\n",
    "print(f\"\\nValidation Performance Comparison:\")\n",
    "print(f\"CatBoost RMSLE: {catboost_1['metrics']['rmsle']:.4f}\")\n",
    "print(f\"XGBoost RMSLE:  {xgboost_1['metrics']['rmsle']:.4f}\")\n",
    "\n",
    "if catboost_1['metrics']['rmsle'] < xgboost_1['metrics']['rmsle']:\n",
    "    print(\"âœ“ CatBoost performed better on validation set\")\n",
    "    best_model = \"CatBoost\"\n",
    "else:\n",
    "    print(\"âœ“ XGBoost performed better on validation set\")\n",
    "    best_model = \"XGBoost\"\n",
    "    \n",
    "print(f\"Recommendation: Consider using {best_model} or the ensemble for final submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2cefae-71ed-44a6-b386-146ab81c433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MODEL COMPARISON AND ANALYSIS\n",
    "# =============================================================================\n",
    "print(\"Analyzing model predictions...\")\n",
    "\n",
    "# Create ensemble predictions (simple average)\n",
    "ensemble_predictions = (catboost_predictions + xgboost_predictions) / 2\n",
    "\n",
    "print(f\"Ensemble predictions range: {ensemble_predictions.min():.1f} - {ensemble_predictions.max():.1f}\")\n",
    "\n",
    "# Display prediction comparison (first 10 rows)\n",
    "print(\"\\nPrediction Comparison (first 10 rows):\")\n",
    "comparison_df = pd.DataFrame({\n",
    "    'id': orig_test_df['id'][:10],\n",
    "    'CatBoost': catboost_predictions[:10],\n",
    "    'XGBoost': xgboost_predictions[:10],\n",
    "    'Ensemble': ensemble_predictions[:10],\n",
    "    'Difference': np.abs(catboost_predictions[:10] - xgboost_predictions[:10])\n",
    "})\n",
    "print(comparison_df.round(2))\n",
    "\n",
    "# Model agreement statistics\n",
    "print(f\"\\nModel Agreement Statistics:\")\n",
    "print(f\"Mean absolute difference: {np.mean(np.abs(catboost_predictions - xgboost_predictions)):.2f}\")\n",
    "print(f\"Max absolute difference: {np.max(np.abs(catboost_predictions - xgboost_predictions)):.2f}\")\n",
    "print(f\"Correlation between models: {np.corrcoef(catboost_predictions, xgboost_predictions)[0,1]:.4f}\")\n",
    "\n",
    "# Validation performance comparison\n",
    "print(f\"\\nValidation Performance Comparison:\")\n",
    "print(f\"CatBoost RMSLE: {catboost_1['metrics']['rmsle']:.4f}\")\n",
    "print(f\"XGBoost RMSLE:  {xgboost_1['metrics']['rmsle']:.4f}\")\n",
    "\n",
    "if catboost_1['metrics']['rmsle'] < xgboost_1['metrics']['rmsle']:\n",
    "    print(\"âœ“ CatBoost performed better on validation set\")\n",
    "    best_model = \"CatBoost\"\n",
    "else:\n",
    "    print(\"âœ“ XGBoost performed better on validation set\")\n",
    "    best_model = \"XGBoost\"\n",
    "    \n",
    "print(f\"Recommendation: Consider using {best_model} or the ensemble for final submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15afb986-b9b3-4d84-b6b1-aed870020a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CREATE SUBMISSION FILES\n",
    "# =============================================================================\n",
    "print(\"Creating submission files...\")\n",
    "\n",
    "# CatBoost submission\n",
    "catboost_submission = pd.DataFrame({\n",
    "    'id': orig_test_df['id'],\n",
    "    'Calories': catboost_predictions\n",
    "})\n",
    "catboost_submission.to_csv('catboost_submission.csv', index=False)\n",
    "\n",
    "# XGBoost submission\n",
    "xgboost_submission = pd.DataFrame({\n",
    "    'id': orig_test_df['id'],\n",
    "    'Calories': xgboost_predictions\n",
    "})\n",
    "xgboost_submission.to_csv('xgboost_submission.csv', index=False)\n",
    "\n",
    "# Ensemble submission\n",
    "ensemble_submission = pd.DataFrame({\n",
    "    'id': orig_test_df['id'],\n",
    "    'Calories': ensemble_predictions\n",
    "})\n",
    "ensemble_submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(f\"âœ“ CatBoost submission: catboost_submission.csv ({catboost_submission.shape[0]} rows)\")\n",
    "print(f\"âœ“ XGBoost submission: xgboost_submission.csv ({xgboost_submission.shape[0]} rows)\")\n",
    "print(f\"âœ“ Ensemble submission: ensemble_submission.csv ({ensemble_submission.shape[0]} rows)\")\n",
    "\n",
    "# Display sample of ensemble submission\n",
    "print(\"\\nEnsemble Submission Preview:\")\n",
    "print(ensemble_submission.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953b774c-8a0f-45be-b086-b7a90ce7af12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running on Kaggle or locally\n",
    "IN_KAGGLE = os.path.exists('/kaggle/working')\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    # If running on Kaggle, use the built-in submission mechanism\n",
    "    print(\"Running on Kaggle - please use the 'Submit' button in the UI to submit your results\")\n",
    "else:\n",
    "    # If running locally, use the Kaggle API to submit\n",
    "    print(\"Submitting via Kaggle API...\")\n",
    "    \n",
    "    # Ensure Kaggle API is installed\n",
    "    try:\n",
    "        import kaggle\n",
    "    except ImportError:\n",
    "        print(\"Kaggle API not found. Installing...\")\n",
    "        !pip install kaggle\n",
    "        import kaggle\n",
    "    \n",
    "    # Submit the file\n",
    "    # Note: Make sure you have Kaggle API credentials set up (~/.kaggle/kaggle.json)\n",
    "    competition_name = \"playground-series-s5e5\"\n",
    "    submission_message = \"xgboost with feature engineering\"\n",
    "    \n",
    "    # Command to submit \n",
    "    submission_command = f\"kaggle competitions submit -c {competition_name} -f submission.csv -m \\\"{submission_message}\\\"\"\n",
    "    \n",
    "    print(f\"Running command: {submission_command}\")\n",
    "    !{submission_command}\n",
    "    \n",
    "    # Check your submissions (optional)\n",
    "    print(\"\\nYour recent submissions:\")\n",
    "    !kaggle competitions submissions -c {competition_name}\n",
    "    \n",
    "print(\"\\nDone! ðŸŽ‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b108a0-e67a-4eea-9505-7d5df78683fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3261f4-4402-4a66-8b82-9eee65330870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
